{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ba0b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T02:30:03.910673Z",
     "iopub.status.busy": "2026-01-07T02:30:03.910137Z",
     "iopub.status.idle": "2026-01-07T02:30:04.542851Z",
     "shell.execute_reply": "2026-01-07T02:30:04.540645Z"
    },
    "papermill": {
     "duration": 0.640117,
     "end_time": "2026-01-07T02:30:04.546863",
     "exception": false,
     "start_time": "2026-01-07T02:30:03.906746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 18 个CSV文件待处理\n",
      "\n",
      "所有文件处理完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    先尝试用标准 csv 解析；失败再退到暴力正则清洗\n",
    "    \"\"\"\n",
    "    # print(f\"\\n处理文件: {file_path}\")\n",
    "\n",
    "    # 0. 先按“正常 csv”读一次\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "        # 如果列名里出现大量空列，也算失败\n",
    "        if df.shape[1] > 50 or df.columns.str.contains('Unnamed').sum() > df.shape[1] // 2:\n",
    "            raise pd.errors.ParserError(\"大量空列，视为脏文件\")\n",
    "        # print(\"✅ 标准 csv 读取成功，跳过暴力清洗\")\n",
    "    except (pd.errors.ParserError, UnicodeDecodeError, KeyError):\n",
    "        print(\"⚠️  标准 csv 解析失败，进入暴力正则清洗...\")\n",
    "        df = _dirty_csv_handler(file_path)   # 你的老逻辑封装一下\n",
    "\n",
    "    # 1. 统一补零、加序号、写文件\n",
    "    new_path = file_path.replace('.csv', '_filled.csv')\n",
    "    df = _post_process(df, new_path)          # 把路径显式传进去\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------ 下面只是把原来的“暴力清洗”抽出来，方便复用 ------------\n",
    "def _dirty_csv_handler(file_path):\n",
    "    \"\"\"你原来的正则清洗逻辑，原封不动搬进来\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    processed_lines, max_columns = [], 0\n",
    "    import re\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # 只有脏文件才暴力替换\n",
    "        normalized_line = re.sub(r'\\s+', ',', line)\n",
    "        parts = [p.strip() for p in normalized_line.split(',') if p.strip()]\n",
    "        max_columns = max(max_columns, len(parts))\n",
    "        processed_lines.append(parts)\n",
    "\n",
    "    # 补列\n",
    "    uniform_data = []\n",
    "    for parts in processed_lines:\n",
    "        while len(parts) < max_columns:\n",
    "            parts.append('0')\n",
    "        uniform_data.append(parts)\n",
    "\n",
    "    df = pd.DataFrame(uniform_data)\n",
    "    return df\n",
    "\n",
    "def _post_process(df: pd.DataFrame, new_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1. 空值 / NaN / \"提取失败\" → 置 0\n",
    "    2. 在最前面插入一行“列序号”，**保留原有表头**\n",
    "    3. 写入 CSV：第 1 行序号，第 2 行表头，第 3 行起数据\n",
    "    \"\"\"\n",
    "    # 1. 置零处理（跳过即将写入的序号行，只处理原数据）\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.columns)):\n",
    "            val = df.iat[i, j]\n",
    "            val_str = str(val).strip()\n",
    "            if pd.isna(val) or val_str == '' or val_str.lower() == 'nan' or val_str == '提取失败':\n",
    "                df.iat[i, j] = 0\n",
    "\n",
    "    # 2. 构造序号行\n",
    "    index_row = [str(i + 1) for i in range(df.shape[1])]\n",
    "\n",
    "    # 3. 写文件：先序号行 → 再带表头的数据\n",
    "    with open(new_path, 'w', encoding='utf-8-sig') as f:\n",
    "        # 第 1 行：序号\n",
    "        f.write(','.join(index_row) + '\\n')\n",
    "        # 第 2 行起：DataFrame（带表头）\n",
    "        df.to_csv(f, index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "    # print(f\"✅ 已保存: {new_path}  （第1行为序号，第2行为原表头）\")\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：批量处理CSV文件\"\"\"\n",
    "    # 获取当前目录中的所有.csv文件\n",
    "    csv_files = [file for file in os.listdir('.') \n",
    "                 if file.endswith('.csv') \n",
    "                 and not file.endswith('_filled.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"当前目录中没有找到CSV文件。\")\n",
    "        return\n",
    "    \n",
    "    print(f\"找到 {len(csv_files)} 个CSV文件待处理\")\n",
    "    \n",
    "    # 处理每个文件\n",
    "    for csv_file in csv_files:\n",
    "        process_csv_file(csv_file)\n",
    "    \n",
    "    print(f\"\\n所有文件处理完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0195e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T02:30:04.559400Z",
     "iopub.status.busy": "2026-01-07T02:30:04.558766Z",
     "iopub.status.idle": "2026-01-07T02:30:04.917496Z",
     "shell.execute_reply": "2026-01-07T02:30:04.916124Z"
    },
    "papermill": {
     "duration": 0.371418,
     "end_time": "2026-01-07T02:30:04.921852",
     "exception": false,
     "start_time": "2026-01-07T02:30:04.550434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 源文件夹路径（包含要移动的.csv文件）\n",
    "source_folder = r\"/path/to/file\"  # 替换为你的源文件夹路径\n",
    "# 目标文件夹路径（文件将被移动到这个位置）\n",
    "destination_folder = r\"/path/to/file\"  # 替换为目标文件夹路径\n",
    "\n",
    "# 确保目标文件夹存在，如果不存在则创建\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# 遍历源文件夹中的所有文件\n",
    "for filename in os.listdir(source_folder):\n",
    "    # 检查文件扩展名是否为.csv\n",
    "    if filename.endswith(\"filled.csv\"):\n",
    "        # 构造完整的文件路径\n",
    "        source_file_path = os.path.join(source_folder, filename)\n",
    "        destination_file_path = os.path.join(destination_folder, filename)\n",
    "        \n",
    "        # 移动文件\n",
    "        shutil.copy(source_file_path, destination_file_path)\n",
    "        print(f\"移动文件：{filename} 到 {destination_folder}\")\n",
    "\n",
    "\n",
    "# 遍历源文件夹中的所有文件\n",
    "for filename in os.listdir(source_folder):\n",
    "    # 检查文件扩展名是否为.csv\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(filename)\n",
    "\n",
    "\n",
    "print(\"所有.csv文件已移动完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.442822,
   "end_time": "2026-01-07T02:30:05.370376",
   "environment_variables": {},
   "exception": null,
   "input_path": "file_utils.ipynb",
   "output_path": "file_utils.ipynb",
   "parameters": {},
   "start_time": "2026-01-07T02:30:01.927554",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
